<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Audio Transcription</title>
    <style>
        body {
            background-color: black;
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
        }
        #transcript {
            text-align: center;
            font-size: 50px;
        }
        #controls {
            position: absolute;
            top: 10px;
            left: 10px;
            font-size: 18px;
        }
    </style>
</head>
<body>
    <div id="transcript">Initializing...</div>
    <div id="controls">
        Font Size: <span id="fontSizeDisplay">50</span>px<br>
        Fade Duration: <span id="fadeDurationDisplay">500</span>ms
    </div>
    <script>
        let selectedMic = null;
        let transcriptElement = document.getElementById('transcript');
        let fontSizeDisplay = document.getElementById('fontSizeDisplay');
        let fadeDurationDisplay = document.getElementById('fadeDurationDisplay');
        let recognition;
        let fontSize = 50;
        let fadeDuration = 500;
        let timeoutId;

        function startTranscription() {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = (event) => {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        transcript += event.results[i][0].transcript + ' ';
                    }
                }
                displayTranscript(transcript);
            };

            recognition.onend = () => {
                startTranscription(); // Restart recognition when it stops
            };

            recognition.start();
        }

        function displayTranscript(text) {
            clearTimeout(timeoutId); // Clear the previous timeout
            transcriptElement.textContent = text;

            if (text.trim()) {
                timeoutId = setTimeout(() => {
                    transcriptElement.style.opacity = '0';
                    setTimeout(() => {
                        transcriptElement.textContent = '';
                        transcriptElement.style.opacity = '1';
                    }, fadeDuration);
                }, 500);
            }
        }

        document.addEventListener('keydown', (event) => {
            if (event.key === 'M' || event.key === 'm') {
                // Logic to select microphone
                alert('Microphone selection feature is under development.');
            } else if (event.key === 'ArrowUp') {
                fontSize += 2;
                transcriptElement.style.fontSize = fontSize + 'px';
                fontSizeDisplay.textContent = fontSize;
            } else if (event.key === 'ArrowDown') {
                fontSize -= 2;
                transcriptElement.style.fontSize = fontSize + 'px';
                fontSizeDisplay.textContent = fontSize;
            } else if (event.key === 'ArrowLeft') {
                fadeDuration -= 50;
                fadeDurationDisplay.textContent = fadeDuration;
            } else if (event.key === 'ArrowRight') {
                fadeDuration += 50;
                fadeDurationDisplay.textContent = fadeDuration;
            }
        });

        startTranscription();
    </script>
</body>
</html>
